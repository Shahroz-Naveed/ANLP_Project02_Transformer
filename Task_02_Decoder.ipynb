{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e26aece9fad407a88d61585644fdf7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c53e13ffedd14861850ac8a7975cf7cc",
              "IPY_MODEL_a656fedb065741c6a48075e1f928d419",
              "IPY_MODEL_0d2bda274d5c4097844a38d00bc5a5c4"
            ],
            "layout": "IPY_MODEL_1b627e4d85ae443b91c3a8f83cda9bda"
          }
        },
        "c53e13ffedd14861850ac8a7975cf7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da8be0f542a472eb8ce9a3b9ed0034c",
            "placeholder": "​",
            "style": "IPY_MODEL_395e07e6c02040618f688c75b60c11f5",
            "value": "Tokenizing train: 100%"
          }
        },
        "a656fedb065741c6a48075e1f928d419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aae54fa03c134ceb8271995ae7e9430f",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32d63b41fad04a2ba1876f02ad177a1e",
            "value": 4000
          }
        },
        "0d2bda274d5c4097844a38d00bc5a5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e686d580be641f8bd4061924d037833",
            "placeholder": "​",
            "style": "IPY_MODEL_177446c490f54d31beb9cea776dbb4b0",
            "value": " 4000/4000 [00:06&lt;00:00, 562.18 examples/s]"
          }
        },
        "1b627e4d85ae443b91c3a8f83cda9bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da8be0f542a472eb8ce9a3b9ed0034c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395e07e6c02040618f688c75b60c11f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aae54fa03c134ceb8271995ae7e9430f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d63b41fad04a2ba1876f02ad177a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e686d580be641f8bd4061924d037833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177446c490f54d31beb9cea776dbb4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "112af08618924bc4b79ba75e5338c0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_252b67b53d2d4afbb177a1fd47a2d220",
              "IPY_MODEL_22428b2863e24392957db16f85ca615d",
              "IPY_MODEL_9690036d906a4c5d8d9220e010932931"
            ],
            "layout": "IPY_MODEL_0d1e5812dbcc48d5b1592953ab9eb6b3"
          }
        },
        "252b67b53d2d4afbb177a1fd47a2d220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1be443caac245338dd231693b26d3aa",
            "placeholder": "​",
            "style": "IPY_MODEL_cd4ac34e820d4695847b4ad772b5449c",
            "value": "Tokenizing validation: 100%"
          }
        },
        "22428b2863e24392957db16f85ca615d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e5ecf34600048f5aa4a5f7dde61c896",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9a8a8a31469459fa4f2469d678854a6",
            "value": 500
          }
        },
        "9690036d906a4c5d8d9220e010932931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4416823bee574b63a8e051e3113d90dd",
            "placeholder": "​",
            "style": "IPY_MODEL_61a85a03c48a435d9b15aa89904cc29d",
            "value": " 500/500 [00:00&lt;00:00, 615.24 examples/s]"
          }
        },
        "0d1e5812dbcc48d5b1592953ab9eb6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1be443caac245338dd231693b26d3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4ac34e820d4695847b4ad772b5449c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e5ecf34600048f5aa4a5f7dde61c896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a8a8a31469459fa4f2469d678854a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4416823bee574b63a8e051e3113d90dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a85a03c48a435d9b15aa89904cc29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b747e617aef471abed5a021285d7008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbf044e177ff46e1925e28c273603342",
              "IPY_MODEL_64ef8f67540c4ae6b050dc5b78edc096",
              "IPY_MODEL_497bbeff423e4e23b6678412fe9b0506"
            ],
            "layout": "IPY_MODEL_a6f5dccebfb74bbbb948de5c74522139"
          }
        },
        "cbf044e177ff46e1925e28c273603342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4934108be9df417c8e3104b5b6146283",
            "placeholder": "​",
            "style": "IPY_MODEL_1bd4231be4dd497f8ea16b60cb1ba4a2",
            "value": "Downloading builder script: "
          }
        },
        "64ef8f67540c4ae6b050dc5b78edc096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb47b2b7e4ec44488ff99936b0e0f3cf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7087a18b220941328e1e93d217ec3f19",
            "value": 1
          }
        },
        "497bbeff423e4e23b6678412fe9b0506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b48771d31bd405691c98bcbdf14abd3",
            "placeholder": "​",
            "style": "IPY_MODEL_b17d635e0501411ca42b0269a6f78d55",
            "value": " 6.27k/? [00:00&lt;00:00, 340kB/s]"
          }
        },
        "a6f5dccebfb74bbbb948de5c74522139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4934108be9df417c8e3104b5b6146283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd4231be4dd497f8ea16b60cb1ba4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb47b2b7e4ec44488ff99936b0e0f3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7087a18b220941328e1e93d217ec3f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b48771d31bd405691c98bcbdf14abd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17d635e0501411ca42b0269a6f78d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxKv4fGf91fS",
        "outputId": "79930bc4-9086-4a1a-c711-7a30322b8e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install Required Libraries\n",
        "!pip install -q transformers datasets torch accelerate evaluate rouge-score nltk kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import Libraries\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    GPT2Tokenizer,\n",
        "    GPT2LMHeadModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from evaluate import load\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9zi-Op8-SFw",
        "outputId": "2f9d4b78-cbb7-4fd2-9314-062b35ca8225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "Memory: 15.83 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Check GPU Availability\n",
        "# ----------------------------------------------------------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"No GPU available. Training will be slower on CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESJuXXJQ-lNN",
        "outputId": "092f24ab-7b0d-4cd0-9451-83274fbce281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "CUDA Version: 12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load Dataset from Current Folder\n",
        "import glob\n",
        "# Find all CSV files in the current directory\n",
        "csv_files = glob.glob('/content/drive/MyDrive/Colab/Task_02_Decoder/dataset.csv')\n",
        "print(f\"Found CSV files in Task_02_Decoder folder: {csv_files}\")\n",
        "# Load the recipe dataset\n",
        "df = pd.read_csv(csv_files[0])\n",
        "print(f\"\\nDataset loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Column names: {df.columns.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQADfGrYcHQC",
        "outputId": "ea9a5c34-55a0-4403-c692-72e37f5d0c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found CSV files in Task_02_Decoder folder: ['/content/drive/MyDrive/Colab/Task_02_Decoder/dataset.csv']\n",
            "\n",
            "Dataset loaded successfully!\n",
            "Dataset shape: (2231143, 6)\n",
            "Column names: ['title', 'NER', 'Extended_NER', 'genre', 'label', 'directions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Explore the Dataset\n",
        "print(\"DATASET EXPLORATION\")\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "# Display first few rows\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "print(df.head(3))\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "# Display sample recipe\n",
        "if len(df) > 0:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SAMPLE RECIPE:\")\n",
        "    print(\"=\"*70)\n",
        "    sample = df.iloc[0]\n",
        "    for col in df.columns:\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(str(sample[col])[:200] + ('...' if len(str(sample[col])) > 200 else ''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXIkcsy5cJmn",
        "outputId": "c3981c99-fb30-4e60-c75b-8def2a034d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET EXPLORATION\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2231143 entries, 0 to 2231142\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Dtype \n",
            "---  ------        ----- \n",
            " 0   title         object\n",
            " 1   NER           object\n",
            " 2   Extended_NER  object\n",
            " 3   genre         object\n",
            " 4   label         int64 \n",
            " 5   directions    object\n",
            "dtypes: int64(1), object(5)\n",
            "memory usage: 102.1+ MB\n",
            "None\n",
            "\n",
            "First 3 rows:\n",
            "                            title  \\\n",
            "0    \\t Arugula Pomegranate Salad   \n",
            "1  \\t Black Bean And Turkey Chili   \n",
            "2  \\t Finger Lickin' Tofu Nuggets   \n",
            "\n",
            "                                                 NER  \\\n",
            "0  [\"baby spinach\", \"baby arugula\", \"pomegranate ...   \n",
            "1  [\"olive oil\", \"yellow onion\", \"garlic\", \"groun...   \n",
            "2  [\"extra firm\", \"almond flour\", \"nutritional ye...   \n",
            "\n",
            "                                        Extended_NER       genre  label  \\\n",
            "0  ['alfalfa sprouts', 'baby spinach', 'baby arug...  vegetables      4   \n",
            "1  ['one', 'yellow onion', 'tomato paste', 'about...       sides      8   \n",
            "2  ['extra firm', '2', 'coconut oil', 'almond flo...      nonveg      3   \n",
            "\n",
            "                                          directions  \n",
            "0  [\"Toss together spinach and arugula, then plac...  \n",
            "1  [\"Dice the onion and mince the garlic. Add the...  \n",
            "2  [\"Wrap the tofu in a clean tea towel and press...  \n",
            "\n",
            "Missing values:\n",
            "title           1\n",
            "NER             0\n",
            "Extended_NER    0\n",
            "genre           0\n",
            "label           0\n",
            "directions      0\n",
            "dtype: int64\n",
            "\n",
            "======================================================================\n",
            "SAMPLE RECIPE:\n",
            "======================================================================\n",
            "\n",
            "title:\n",
            "\t Arugula Pomegranate Salad\n",
            "\n",
            "NER:\n",
            "[\"baby spinach\", \"baby arugula\", \"pomegranate arils\", \"persimmon\", \"alfalfa sprouts\"]\n",
            "\n",
            "Extended_NER:\n",
            "['alfalfa sprouts', 'baby spinach', 'baby arugula', 'pomegranate arils', 'persimmon']\n",
            "\n",
            "genre:\n",
            "vegetables\n",
            "\n",
            "label:\n",
            "4\n",
            "\n",
            "directions:\n",
            "[\"Toss together spinach and arugula, then place in your serving bowl.\", \"Remove the stem and leaves of the persimmon, then slice into thin wedges.\", \"Arrange the persimmon on top of the spinach and ar...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Identify and Standardize Column Names\n",
        "print(\"IDENTIFYING DATASET STRUCTURE\")\n",
        "# Find relevant columns\n",
        "title_col = None\n",
        "ingredients_col = None\n",
        "directions_col = None\n",
        "# Common column name patterns\n",
        "for col in df.columns:\n",
        "    col_lower = col.lower()\n",
        "    if any(x in col_lower for x in ['title', 'name', 'recipe']):\n",
        "        title_col = col\n",
        "    elif any(x in col_lower for x in ['ingredient']):\n",
        "        ingredients_col = col\n",
        "    elif any(x in col_lower for x in ['direction', 'instruction', 'step', 'method']):\n",
        "        directions_col = col\n",
        "print(f\"Identified columns:\")\n",
        "print(f\"  Title column: {title_col}\")\n",
        "print(f\"  Ingredients column: {ingredients_col}\")\n",
        "print(f\"  Directions/Instructions column: {directions_col}\")\n",
        "# Verify we found all required columns\n",
        "if not all([title_col, ingredients_col, directions_col]):\n",
        "    print(\"\\nWarning: Could not auto-detect all columns. Please verify manually.\")\n",
        "    print(\"Available columns:\", df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oegAubo-cJyp",
        "outputId": "eeab2750-b5f7-48e7-9bad-34977f0574e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDENTIFYING DATASET STRUCTURE\n",
            "Identified columns:\n",
            "  Title column: title\n",
            "  Ingredients column: None\n",
            "  Directions/Instructions column: directions\n",
            "\n",
            "Warning: Could not auto-detect all columns. Please verify manually.\n",
            "Available columns: ['title', 'NER', 'Extended_NER', 'genre', 'label', 'directions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Data Cleaning and Preprocessing\n",
        "print(\"DATA PREPROCESSING\")\n",
        "# Keep only required columns and remove missing values\n",
        "required_cols = [title_col, 'NER', directions_col]\n",
        "df_clean = df[required_cols].copy()\n",
        "original_size = len(df_clean)\n",
        "df_clean = df_clean.dropna()\n",
        "print(f\"Removed {original_size - len(df_clean)} rows with missing values\")\n",
        "# Remove duplicate recipes (based on title)\n",
        "df_clean = df_clean.drop_duplicates(subset=[title_col])\n",
        "print(f\"Removed duplicates. Final dataset size: {len(df_clean)}\")\n",
        "# Rename columns for consistency\n",
        "df_clean.columns = ['title', 'ingredients', 'directions']\n",
        "# Convert all to string type\n",
        "for col in df_clean.columns:\n",
        "    df_clean[col] = df_clean[col].astype(str)\n",
        "\n",
        "print(f\"\\nCleaned dataset shape: {df_clean.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCAiCfQ4cJ-I",
        "outputId": "983b514f-b81d-4621-dae2-39ad358654be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA PREPROCESSING\n",
            "Removed 1 rows with missing values\n",
            "Removed duplicates. Final dataset size: 1312864\n",
            "\n",
            "Cleaned dataset shape: (1312864, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cell 8: Limit Dataset Size (Optional for Faster Training)\n",
        "# # ----------------------------------------------------------------------------\n",
        "# # For demonstration and faster training, we'll use a subset\n",
        "# # Remove this cell or adjust SAMPLE_SIZE for full dataset training\n",
        "SAMPLE_SIZE = 5000  # Adjust based on your needs and GPU memory\n",
        "\n",
        "if len(df_clean) > SAMPLE_SIZE:\n",
        "    df_clean = df_clean.sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
        "    print(f\"Using sample of {SAMPLE_SIZE} recipes for training\")\n",
        "else:\n",
        "    print(f\"Using full dataset of {len(df_clean)} recipes\")\n",
        "\n",
        "# Analyze text lengths\n",
        "df_clean['total_length'] = df_clean.apply(\n",
        "    lambda row: len(row['title']) + len(row['ingredients']) + len(row['directions']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(f\"\\nText length statistics (characters):\")\n",
        "print(df_clean['total_length'].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eURz67EncKGS",
        "outputId": "8362ff8e-8906-46bc-ff52-7404d8b2aa6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using sample of 5000 recipes for training\n",
            "\n",
            "Text length statistics (characters):\n",
            "count    5000.000000\n",
            "mean      744.024000\n",
            "std       520.322948\n",
            "min        67.000000\n",
            "25%       386.000000\n",
            "50%       603.000000\n",
            "75%       951.000000\n",
            "max      6032.000000\n",
            "Name: total_length, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Format Recipes for GPT-2 Training\n",
        "# ----------------------------------------------------------------------------\n",
        "print(\"FORMATTING RECIPES FOR GPT-2\")\n",
        "def format_recipe(row):\n",
        "    \"\"\"\n",
        "    Format recipe into structured text for GPT-2\n",
        "    Format: Recipe: [title] | Ingredients: [ingredients] | Instructions: [directions]\n",
        "    \"\"\"\n",
        "    title = row['title'].strip()\n",
        "    ingredients = row['ingredients'].strip()\n",
        "    directions = row['directions'].strip()\n",
        "    # Create structured format\n",
        "    formatted = f\"Recipe: {title} | Ingredients: {ingredients} | Instructions: {directions}\"\n",
        "    return formatted\n",
        "# Apply formatting\n",
        "print(\"Formatting all recipes...\")\n",
        "df_clean['formatted_text'] = df_clean.apply(format_recipe, axis=1)\n",
        "\n",
        "# Display sample formatted recipes\n",
        "print(\"\\nSample Formatted Recipes:\")\n",
        "for i in range(min(3, len(df_clean))):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Recipe {i+1}:\")\n",
        "    print(df_clean['formatted_text'].iloc[i][:300] + \"...\")\n",
        "\n",
        "# Analyze formatted text lengths\n",
        "df_clean['formatted_length'] = df_clean['formatted_text'].str.len()\n",
        "print(f\"\\nFormatted text length statistics:\")\n",
        "print(df_clean['formatted_length'].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9XqQksiij-s",
        "outputId": "c8f35fce-2f66-43df-ff3b-261e7788bd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FORMATTING RECIPES FOR GPT-2\n",
            "Formatting all recipes...\n",
            "\n",
            "Sample Formatted Recipes:\n",
            "\n",
            "======================================================================\n",
            "Recipe 1:\n",
            "Recipe: Ham Steaks With Jazzed-Up Gravy | Ingredients: [\"butter\", \"brown sugar\", \"ham steaks\", \"pepper\", \"green onion\", \"mushrooms\", \"flour\", \"chicken broth\", \"coffee\"] | Instructions: [\"Melt the butter and brown sugar in a heavy skillet.\", \"Season the ham steaks with pepper.\", \"Cook the ham steaks ...\n",
            "\n",
            "======================================================================\n",
            "Recipe 2:\n",
            "Recipe: Walnut Muffins | Ingredients: [\"flour\", \"sugar\", \"baking powder\", \"butter\", \"eggs\", \"milk\", \"fruit\", \"walnuts\"] | Instructions: Whisk all wet ingredients together. Mix all dry ingredients together. Add wet mixture to dry mixture. Next add fruit and nuts. Grease muffin tins. Bake at 350\\u00b0...\n",
            "\n",
            "======================================================================\n",
            "Recipe 3:\n",
            "Recipe: Pumpkin Chocolate Chip Waffles | Ingredients: [\"flour\", \"baking powder\", \"baking soda\", \"pumpkin pie spice\", \"salt\", \"eggs\", \"brown sugar\", \"pumpkin\", \"milk\", \"chocolate chips\", \"margarine\", \"orange\", \"apples\", \"butter\", \"syrup\"] | Instructions: [\"Make waffle batter (all above ingredients mi...\n",
            "\n",
            "Formatted text length statistics:\n",
            "count    5000.000000\n",
            "mean      784.916800\n",
            "std       520.338642\n",
            "min       108.000000\n",
            "25%       427.000000\n",
            "50%       644.000000\n",
            "75%       992.000000\n",
            "max      6073.000000\n",
            "Name: formatted_length, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Train-Validation-Test Split\n",
        "print(\"DATASET SPLITTING\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split: 80% train, 10% validation, 10% test\n",
        "# First split: 80% train, 20% temp\n",
        "train_df, temp_df = train_test_split(\n",
        "    df_clean[['formatted_text']],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "# Second split: split temp into 50-50 for validation and test\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "print(f\"Train set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")\n",
        "print(f\"Split ratio - Train:Val:Test = {len(train_df)}:{len(val_df)}:{len(test_df)}\")\n",
        "# Verify split percentages\n",
        "total = len(train_df) + len(val_df) + len(test_df)\n",
        "print(f\"\\nSplit percentages:\")\n",
        "print(f\"  Train: {len(train_df)/total*100:.1f}%\")\n",
        "print(f\"  Validation: {len(val_df)/total*100:.1f}%\")\n",
        "print(f\"  Test: {len(test_df)/total*100:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw9kuksXikJH",
        "outputId": "11442c75-6492-40b3-e1e3-cc4636b6990a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET SPLITTING\n",
            "Train set size: 4000\n",
            "Validation set size: 500\n",
            "Test set size: 500\n",
            "Split ratio - Train:Val:Test = 4000:500:500\n",
            "\n",
            "Split percentages:\n",
            "  Train: 80.0%\n",
            "  Validation: 10.0%\n",
            "  Test: 10.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Convert to Hugging Face Dataset Format\n",
        "# Create HuggingFace datasets for all three splits\n",
        "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
        "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "print(\"Dataset converted to HuggingFace format:\")\n",
        "print(dataset_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZB-s9uYikSY",
        "outputId": "586ccf03-bcab-4d31-efd9-c7f5f8fa7b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset converted to HuggingFace format:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['formatted_text'],\n",
            "        num_rows: 4000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['formatted_text'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['formatted_text'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Load GPT-2 Tokenizer\n",
        "print(\"LOADING GPT-2 TOKENIZER\")\n",
        "model_name = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "# GPT-2 doesn't have a pad token by default, so we set it to eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'left'  # Padding on the left for generation\n",
        "print(f\"Tokenizer: {model_name}\")\n",
        "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
        "print(f\"EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")\n",
        "print(f\"PAD token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})\")\n",
        "print(f\"Max length: {tokenizer.model_max_length}\")\n",
        "# Test tokenization\n",
        "sample_text = df_clean['formatted_text'].iloc[0][:200]\n",
        "print(f\"\\nExample tokenization:\")\n",
        "print(f\"Input: {sample_text}...\")\n",
        "encoded = tokenizer(sample_text, truncation=True, max_length=50)\n",
        "print(f\"Tokens: {len(encoded['input_ids'])} tokens\")\n",
        "print(f\"First 15 token IDs: {encoded['input_ids'][:15]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP3Znl16ikb4",
        "outputId": "c3b8be7e-7585-4e51-facb-303938b59c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING GPT-2 TOKENIZER\n",
            "Tokenizer: gpt2\n",
            "Vocabulary size: 50257\n",
            "EOS token: <|endoftext|> (ID: 50256)\n",
            "PAD token: <|endoftext|> (ID: 50256)\n",
            "Max length: 1024\n",
            "\n",
            "Example tokenization:\n",
            "Input: Recipe: Ham Steaks With Jazzed-Up Gravy | Ingredients: [\"butter\", \"brown sugar\", \"ham steaks\", \"pepper\", \"green onion\", \"mushrooms\", \"flour\", \"chicken broth\", \"coffee\"] | Instructions: [\"Melt the butt...\n",
            "Tokens: 50 tokens\n",
            "First 15 token IDs: [37523, 25, 4345, 2441, 4730, 2080, 21406, 276, 12, 4933, 32599, 88, 930, 33474, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Tokenize Datasets\n",
        "print(\"TOKENIZING DATASETS\")\n",
        "# Define tokenization function\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenize the formatted recipe texts\n",
        "    Using max_length of 512 tokens for full recipes\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        examples['formatted_text'],\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding='max_length'\n",
        "    )\n",
        "# Apply tokenization\n",
        "print(\"Tokenizing training set...\")\n",
        "tokenized_train = dataset_dict['train'].map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=['formatted_text'],\n",
        "    desc=\"Tokenizing train\"\n",
        ")\n",
        "print(\"Tokenizing validation set...\")\n",
        "tokenized_val = dataset_dict['validation'].map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=['formatted_text'],\n",
        "    desc=\"Tokenizing validation\"\n",
        ")\n",
        "# Create final tokenized dataset\n",
        "tokenized_datasets = DatasetDict({\n",
        "    'train': tokenized_train,\n",
        "    'validation': tokenized_val\n",
        "})\n",
        "print(\"\\nTokenization complete!\")\n",
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "5e26aece9fad407a88d61585644fdf7c",
            "c53e13ffedd14861850ac8a7975cf7cc",
            "a656fedb065741c6a48075e1f928d419",
            "0d2bda274d5c4097844a38d00bc5a5c4",
            "1b627e4d85ae443b91c3a8f83cda9bda",
            "2da8be0f542a472eb8ce9a3b9ed0034c",
            "395e07e6c02040618f688c75b60c11f5",
            "aae54fa03c134ceb8271995ae7e9430f",
            "32d63b41fad04a2ba1876f02ad177a1e",
            "9e686d580be641f8bd4061924d037833",
            "177446c490f54d31beb9cea776dbb4b0",
            "112af08618924bc4b79ba75e5338c0c7",
            "252b67b53d2d4afbb177a1fd47a2d220",
            "22428b2863e24392957db16f85ca615d",
            "9690036d906a4c5d8d9220e010932931",
            "0d1e5812dbcc48d5b1592953ab9eb6b3",
            "f1be443caac245338dd231693b26d3aa",
            "cd4ac34e820d4695847b4ad772b5449c",
            "9e5ecf34600048f5aa4a5f7dde61c896",
            "b9a8a8a31469459fa4f2469d678854a6",
            "4416823bee574b63a8e051e3113d90dd",
            "61a85a03c48a435d9b15aa89904cc29d"
          ]
        },
        "id": "CndLyV8Vikjj",
        "outputId": "2e559d80-7875-48ff-e389-ed9c768f7dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKENIZING DATASETS\n",
            "Tokenizing training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e26aece9fad407a88d61585644fdf7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing validation set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing validation:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "112af08618924bc4b79ba75e5338c0c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization complete!\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 4000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Load GPT-2 Model\n",
        "print(\"LOADING GPT-2 MODEL\")\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "# Resize token embeddings to match tokenizer\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "# Move model to GPU\n",
        "model = model.to(device)\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Total parameters: {model.num_parameters():,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "print(f\"Model device: {next(model.parameters()).device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx8lrvWPopCC",
        "outputId": "74227dcf-2a87-41fb-c9c4-ddd20536b566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING GPT-2 MODEL\n",
            "Model: gpt2\n",
            "Total parameters: 124,439,808\n",
            "Trainable parameters: 124,439,808\n",
            "Model device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Setup Data Collator for Language Modeling\n",
        "# Data collator for causal language modeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # We're doing causal LM, not masked LM\n",
        ")\n",
        "print(\"Data Collator configured:\")\n",
        "print(\"  Task: Causal Language Modeling\")\n",
        "print(\"  MLM (Masked Language Modeling): False\")\n",
        "print(\"  GPT-2 will learn to predict the next token\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mLQQ0FmopLw",
        "outputId": "c12bb794-f7cb-4a9e-f65c-f640d60b507a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Collator configured:\n",
            "  Task: Causal Language Modeling\n",
            "  MLM (Masked Language Modeling): False\n",
            "  GPT-2 will learn to predict the next token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Configure Training Arguments\n",
        "print(\"CONFIGURING TRAINING\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',                    # Output directory\n",
        "    eval_strategy='epoch',                # Evaluate each epoch\n",
        "    save_strategy='epoch',                      # Save each epoch\n",
        "    learning_rate=5e-5,                        # Learning rate\n",
        "    per_device_train_batch_size=4,             # Batch size for training\n",
        "    per_device_eval_batch_size=4,              # Batch size for evaluation\n",
        "    num_train_epochs=3,                        # Number of epochs\n",
        "    weight_decay=0.01,                         # Weight decay\n",
        "    warmup_steps=100,                          # Warmup steps\n",
        "    logging_dir='./logs',                      # Logging directory\n",
        "    logging_steps=50,                          # Log every N steps\n",
        "    load_best_model_at_end=True,              # Load best model\n",
        "    save_total_limit=2,                        # Keep only 2 checkpoints\n",
        "    fp16=torch.cuda.is_available(),            # Mixed precision\n",
        "    gradient_accumulation_steps=4,             # Accumulate gradients\n",
        "    report_to='none',                          # Don't report externally\n",
        "    disable_tqdm=False,                        # Show progress bars\n",
        ")\n",
        "print(\"Training Arguments:\")\n",
        "print(f\"  Learning Rate: {training_args.learning_rate}\")\n",
        "print(f\"  Train Batch Size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Gradient Accumulation: {training_args.gradient_accumulation_steps}\")\n",
        "print(f\"  Effective Batch Size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  FP16: {training_args.fp16}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YgNiWLNopU1",
        "outputId": "7479d38b-b6d1-4b26-d0ab-bf74360eaf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIGURING TRAINING\n",
            "Training Arguments:\n",
            "  Learning Rate: 5e-05\n",
            "  Train Batch Size: 4\n",
            "  Gradient Accumulation: 4\n",
            "  Effective Batch Size: 16\n",
            "  Epochs: 3\n",
            "  FP16: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "print(\"Trainer initialized successfully!\")\n",
        "print(f\"Training samples: {len(tokenized_datasets['train'])}\")\n",
        "print(f\"Validation samples: {len(tokenized_datasets['validation'])}\")\n",
        "steps_per_epoch = len(tokenized_datasets['train']) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)\n",
        "print(f\"Steps per epoch: {steps_per_epoch}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpzfTHoaopeg",
        "outputId": "cbb5e424-6060-46c2-bb02-bd3a67d1c6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer initialized successfully!\n",
            "Training samples: 4000\n",
            "Validation samples: 500\n",
            "Steps per epoch: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Train the Model\n",
        "print(\"STARTING TRAINING\")\n",
        "print(f\"Training on {device}\")\n",
        "print()\n",
        "# Start training\n",
        "train_result = trainer.train()\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(f\"Training Loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"Training Runtime: {train_result.metrics['train_runtime']:.2f} seconds ({train_result.metrics['train_runtime']/60:.2f} minutes)\")\n",
        "print(f\"Training Samples/Second: {train_result.metrics['train_samples_per_second']:.2f}\")\n",
        "print(f\"Training Steps/Second: {train_result.metrics['train_steps_per_second']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "YE2np9fmikrH",
        "outputId": "11cf6466-1431-4596-8a09-b5cbf2fc9dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING TRAINING\n",
            "Training on cuda\n",
            "This will take approximately 30-40 minutes on a T4 GPU...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 14:51, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.405700</td>\n",
              "      <td>2.238946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.261000</td>\n",
              "      <td>2.172313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.205100</td>\n",
              "      <td>2.155329</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETED!\n",
            "======================================================================\n",
            "Training Loss: 2.5944\n",
            "Training Runtime: 892.38 seconds (14.87 minutes)\n",
            "Training Samples/Second: 13.45\n",
            "Training Steps/Second: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 19: Evaluate on Validation Set\n",
        "print(\"EVALUATING ON VALIDATION SET\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"\\nValidation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "UQNt2iqix_jt",
        "outputId": "351e0140-2c84-41c3-b30b-05b92a97b6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUATING ON VALIDATION SET\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "  eval_loss: 2.1553\n",
            "  eval_runtime: 10.4329\n",
            "  eval_samples_per_second: 47.9250\n",
            "  eval_steps_per_second: 11.9810\n",
            "  epoch: 3.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 20: Define Recipe Generation Function\n",
        "def generate_recipe(prompt, max_length=400, temperature=0.8, top_k=50, top_p=0.95):\n",
        "    \"\"\"\n",
        "    Generate a recipe based on a prompt\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Starting text (e.g., \"Recipe: Chocolate Cake | Ingredients:\")\n",
        "        max_length (int): Maximum length of generated text\n",
        "        temperature (float): Controls randomness (0.1-1.5, higher = more creative)\n",
        "        top_k (int): Limits to top k tokens\n",
        "        top_p (float): Nucleus sampling parameter\n",
        "\n",
        "    Returns:\n",
        "        str: Generated recipe text\n",
        "    \"\"\"\n",
        "    # Encode input\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "    # Generate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "    # Decode\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "print(\"Recipe generation function defined!\")\n",
        "print(\"Usage: generate_recipe('Recipe: [name] | Ingredients:')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH7VABjM4jgp",
        "outputId": "2408a71f-50fc-4e1e-d677-3cd81efa90aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe generation function defined!\n",
            "Usage: generate_recipe('Recipe: [name] | Ingredients:')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 21: Test Recipe Generation with Various Prompts\n",
        "print(\"TESTING RECIPE GENERATION\")\n",
        "# Define test prompts\n",
        "test_prompts = [\n",
        "    \"Recipe: Chocolate Chip Cookies | Ingredients:\",\n",
        "    \"Recipe: Chicken Tikka Masala | Ingredients:\",\n",
        "    \"Recipe: Vegetarian Pasta | Ingredients:\",\n",
        "    \"Recipe: Banana Smoothie | Ingredients:\",\n",
        "    \"Recipe: Grilled Salmon | Ingredients:\"\n",
        "]\n",
        "generated_recipes = []\n",
        "for i, prompt in enumerate(test_prompts, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Test {i}/{len(test_prompts)}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(\"-\"*70)\n",
        "    # Generate recipe\n",
        "    recipe = generate_recipe(prompt, max_length=350, temperature=0.8)\n",
        "    generated_recipes.append({\n",
        "        'prompt': prompt,\n",
        "        'generated_recipe': recipe\n",
        "    })\n",
        "    print(recipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJoXLKlq4jyZ",
        "outputId": "c683a890-8471-454e-9c78-bc890c41cb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTING RECIPE GENERATION\n",
            "\n",
            "======================================================================\n",
            "Test 1/5\n",
            "======================================================================\n",
            "Prompt: Recipe: Chocolate Chip Cookies | Ingredients:\n",
            "----------------------------------------------------------------------\n",
            "Recipe: Chocolate Chip Cookies | Ingredients: [\"baking soda\", \"water\", \"butter\", \"unsalted butter\", \"eggs\", \"milk\", \"salt\", \"unsalted butter\", \"vanilla\", \"milk\", \"brown sugar\", \"vanilla\", \"sugar\", \"flour\", \"salt\", \"egg\", \"sugar\", \"powdered sugar\", \"vanilla\", \"vanilla extract\", \"flour\", \"vanilla\", \"butter\", \"butter\", \"butter\", \"vanilla\", \"cream cheese\", \"sugar\", \"vanilla\", \"butter\", \"butter\", \"white sugar\", \"vanilla\", \"butter\", \"salt\", \"vanilla\"] | Instructions: [\"Preheat oven to 375.\", \"In a small bowl, combine the baking soda, water, butter, eggs, and milk. Add the butter and vanilla, mix well. Pour in the flour, salt, and sugar. Bring to a boil, then reduce heat to medium. Stir in the butter and whisk until smooth. When the mixture has reduced by half, add in the eggs. Stir in the vanilla. Stir well to coat the eggs. Transfer the mixture to a lightly floured surface. Bake for 8-10 minutes or until the egg mixture is slightly browned. Let cool on wire rack for 5 minutes.\", \"Combine flour mixture, salt, and vanilla in a medium bowl. Add the powdered sugar, and beat well until smooth. Add in the flour mixture, and beat gently to combine. Spoon the batter into a greased 9 x 13-in. baking dish.\", \"Bake for 45 minutes or until the base\n",
            "\n",
            "======================================================================\n",
            "Test 2/5\n",
            "======================================================================\n",
            "Prompt: Recipe: Chicken Tikka Masala | Ingredients:\n",
            "----------------------------------------------------------------------\n",
            "Recipe: Chicken Tikka Masala | Ingredients: [\"olive oil\", \"turmeric\", \"salt\", \"mushrooms\", \"pepper\", \"chicken stock\", \"fresh ginger\", \"paprika\", \"garlic\", \"hot pepper\", \"onion\", \"fresh ginger\", \"thyme\", \"thyme leaves\", \"chicken broth\", \"salt\", \"thyme\", \"cayenne pepper\", \"garlic\", \"hot pepper\", \"onion\", \"chicken broth\", \"red onion\", \"chicken stock\", \"hot pepper\", \"onion\", \"red pepper\", \"hot chili pepper\", \"chicken broth\", \"red bell pepper\", \"chicken broth\", \"red onion\", \"red bell pepper\", \"chicken broth\", \"red pepper\", \"hot chili pepper\", \"chicken broth\", \"red bell pepper\", \"chicken broth\", \"red bell pepper\", \"chicken broth\", \"red onion\", \"chicken broth\", \"red pepper\", \"chicken broth\", \"red onion\", \"chicken broth\", \"red bell pepper\", \"chicken broth\", \"red onion\", \"chicken broth\", \"red bell pepper\", \"chicken broth\", \"chicken broth\", \"red onion\", \"chicken broth\", \"red bell pepper\", \"chicken broth\", \"red onion\", \"chicken broth\", \"red peppers\", \"chicken broth\", \"red onion\", \"chicken broth\", \"red pepper\", \"chicken broth\", \"red onion\", \"chicken broth\"] | Instructions: [\"Combine oil, turmeric, salt, pepper, salt and lemon juice in a blender. Blend until smooth. Add chicken\n",
            "\n",
            "======================================================================\n",
            "Test 3/5\n",
            "======================================================================\n",
            "Prompt: Recipe: Vegetarian Pasta | Ingredients:\n",
            "----------------------------------------------------------------------\n",
            "Recipe: Vegetarian Pasta | Ingredients: [\"pasta\", \"sugar\", \"chili powder\", \"balsamic vinegar\", \"salt\", \"egg yolks\", \"salt\", \"ground black pepper\", \"oil\", \"green onions\", \"parsley\", \"chicken broth\", \"black pepper\", \"balsamic vinegar\", \"red bell pepper\", \"ground pepper\", \"ground black pepper\", \"salt\", \"ground black pepper\", \"pepper\", \"pepper\"] | Instructions: [\"Preheat oven to 350 degrees F (175 degrees C). Drain pasta, reserving the pasta for use.\", \"Meanwhile, whisk together the sugar, chili powder, balsamic vinegar, salt, and pepper in a large bowl.\", \"Bring to a boil.\", \"Whisk the egg yolks, salt, and pepper in a medium bowl.\", \"Add the balsamic vinegar, stir to combine.\", \"Add the onions, cook for 1 minute, stirring occasionally, until softened.\", \"Add the ground black pepper, salt, and pepper.\", \"Add the broth, black pepper, and broth to the eggs.\", \"Bring to a boil.\", \"Simmer for 5 minutes, stirring to dissolve the vinegar.\", \"Season with salt and pepper.\", \"Transfer to a large serving bowl.\", \"Set aside.\", \"When ready to serve, stir in the garlic and onion.\", \"Put the spinach in a medium bowl.\", \"Add the tomatoes, chopped chives, parsley, and cilantro, season with salt and pepper.\", \"Cover, and serve with a dollop of Parmesan cheese.\", \"Serve immediately.\", \"Bake at 350 degrees F (175 degrees C). Refriger\n",
            "\n",
            "======================================================================\n",
            "Test 4/5\n",
            "======================================================================\n",
            "Prompt: Recipe: Banana Smoothie | Ingredients:\n",
            "----------------------------------------------------------------------\n",
            "Recipe: Banana Smoothie | Ingredients: [\"brown sugar\", \"flour\", \"sugar\", \"flour\", \"egg yolks\", \"salt\", \"vanilla\", \"vanilla\", \"salt\", \"vanilla\", \"vanilla\", \"soda\", \"vanilla\", \"baking soda\", \"vanilla extract\", \"vanilla\", \"baking soda\", \"vanilla ice\", \"soda\", \"vanilla\", \"egg\", \"vanilla\", \"vanilla\", \"salt\", \"vanilla\", \"vanilla\", \"eggs\", \"sugar\", \"sugar\", \"vanilla\", \"vanilla extract\", \"vanilla extract\", \"vanilla\", \"sugar\", \"vanilla\", \"water\", \"vanilla\", \"vanilla\", \"salt\", \"vanilla\", \"sugar\", \"vanilla\", \"vanilla\"] | Instructions: [\"Prepare the ingredients in a mixing bowl with the dry ingredients, except for the egg yolks.\", \"Mix well and beat until incorporated.\", \"Add the eggs and vanilla extract and mix well.\", \"Add the ice and water to the egg yolks mixture and add to the vanilla.\", \"Mix well and mix well and fold in the vanilla extract.\", \"Cover and refrigerate for at least 1 hour.\", \"If you want to cook the whole batch in batches (or in batches of 12 batches), you can do that by blending the whole batch in a food processor.\", \"You can do this with the mixer or the stand mixer.\", \"It will make the whole batch much better and easier to prepare.\", \"Heat the flour and sugars to medium speed.\", \"Add the eggs and sugar and\n",
            "\n",
            "======================================================================\n",
            "Test 5/5\n",
            "======================================================================\n",
            "Prompt: Recipe: Grilled Salmon | Ingredients:\n",
            "----------------------------------------------------------------------\n",
            "Recipe: Grilled Salmon | Ingredients: [\"salmon\", \"celery\", \"salt\", \"butter\", \"baking powder\", \"freshly ground black pepper\", \"green pepper\", \"pepper\", \"black pepper\", \"freshly ground black pepper\", \"onion\", \"thyme\", \"pepper\", \"ground cumin\", \"freshly ground black pepper\", \"onion\", \"salt\", \"ground black pepper\", \"salt\", \"fresh ground black pepper\", \"sage\", \"olive oil\", \"sage powder\", \"ground cumin\", \"ground black pepper\", \"sage powder\", \"ground cayenne pepper\", \"ground sage\", \"ground pepper\"] | Instructions: [\"Preheat oven to 375F. Grease and line a 9-by-8-inch baking pan with parchment paper.\", \"In a small bowl, whisk together the eggs, salt, black pepper, sage, and pepper.\", \"In another small bowl, whisk together the ground cayenne, sage, and pepper.\", \"Bring to a boil, reduce heat to low, and simmer for about 5 minutes, stirring occasionally.\", \"Remove from heat, and stir in the remaining 2 tablespoons of the cooking oil, and the parsley.\", \"Stir in the egg yolks.\", \"Sprinkle with the basil, and season with the salt and pepper.\", \"Reduce heat to low, and stir in the remaining 2 tablespoons of the cooking oil.\", \"Stir in the basil and remaining 1 tablespoon of the parsley.\", \"Cook until the meat is soft and cooked through, about 1 minute.\", \"Add the remaining 1 tablespoon of the cooking oil, and cook until the meat is thick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 22: Generate Recipes from Custom Ingredients\n",
        "print(\"GENERATING FROM INGREDIENTS\")\n",
        "def generate_from_ingredients(ingredients_list, recipe_name=\"\"):\n",
        "    \"\"\"\n",
        "    Generate a recipe given a list of ingredients\n",
        "\n",
        "    Args:\n",
        "        ingredients_list (list): List of ingredients\n",
        "        recipe_name (str): Optional recipe name\n",
        "\n",
        "    Returns:\n",
        "        str: Generated recipe\n",
        "    \"\"\"\n",
        "    ingredients_str = \", \".join(ingredients_list)\n",
        "    if recipe_name:\n",
        "        prompt = f\"Recipe: {recipe_name} | Ingredients: {ingredients_str} | Instructions:\"\n",
        "    else:\n",
        "        prompt = f\"Recipe: Delicious Dish | Ingredients: {ingredients_str} | Instructions:\"\n",
        "\n",
        "    return generate_recipe(prompt, max_length=400, temperature=0.7)\n",
        "# Test ingredient-based generation\n",
        "ingredient_tests = [\n",
        "    ([\"chicken breast\", \"tomatoes\", \"onions\", \"garlic\", \"olive oil\"], \"Italian Chicken\"),\n",
        "    ([\"eggs\", \"milk\", \"flour\", \"sugar\", \"butter\"], \"Pancakes\"),\n",
        "    ([\"pasta\", \"cheese\", \"cream\", \"black pepper\"], \"Cacio e Pepe\")\n",
        "]\n",
        "print(\"\\nGenerating recipes from ingredients:\")\n",
        "for ingredients, name in ingredient_tests:\n",
        "    print(f\"Ingredients: {', '.join(ingredients)}\")\n",
        "    print(f\"Recipe Name: {name}\")\n",
        "    recipe = generate_from_ingredients(ingredients, name)\n",
        "    print(recipe)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd4CdhK44kIV",
        "outputId": "08bfc09d-449b-43a8-ef4a-02294f0f3808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATING FROM INGREDIENTS\n",
            "\n",
            "Generating recipes from ingredients:\n",
            "Ingredients: chicken breast, tomatoes, onions, garlic, olive oil\n",
            "Recipe Name: Italian Chicken\n",
            "Recipe: Italian Chicken | Ingredients: chicken breast, tomatoes, onions, garlic, olive oil | Instructions: [\"Cut chicken into quarters and bring to a boil. Drain and cool.\", \"In a large saucepan, heat 1/4 cup of the chicken broth. Add garlic powder, onion powder and 1/2 cup of the water. Bring to a boil. Reduce heat to medium and simmer for 10 minutes. Remove chicken from heat, add 1/2 cup of the water and cook, stirring, until chicken is tender, about 5 minutes. Remove from heat and allow to cool.\", \"In a large saucepan, heat 1 cup of the chicken broth. Add 1/4 cup of the chicken broth and bring to a boil. Reduce heat to medium and simmer for 10 minutes. Remove from heat and allow to cool.\", \"In a large saucepan, heat 1 cup of the chicken broth. Add 1/4 cup of the water and bring to a boil. Reduce heat to medium and simmer for 10 minutes. Remove chicken from heat and allow to cool.\", \"In a large saucepan, heat 1 cup of the chicken broth. Add 1/2 cup of the water and bring to a boil. Reduce heat to medium and simmer for 10 minutes. Remove chicken from heat and allow to cool.\", \"In a large saucepan, heat 1 cup of the chicken broth. Add 1/4 cup of the chicken broth and bring to a boil. Reduce heat to medium and simmer for 10 minutes. Remove chicken from heat and allow to cool.\", \"In a large saucepan, heat 1 cup of the chicken broth. Add 1/4 cup of the chicken broth and bring to a boil. Reduce heat to medium and simmer for 10 minutes. Remove chicken from heat and allow to cool.\", \"In a large saucepan, heat 1 cup of the chicken broth. Add 1/4 cup of the chicken broth and bring to a boil. Reduce heat to medium and simmer for 10 minutes.\n",
            "\n",
            "Ingredients: eggs, milk, flour, sugar, butter\n",
            "Recipe Name: Pancakes\n",
            "Recipe: Pancakes | Ingredients: eggs, milk, flour, sugar, butter | Instructions: [\"Preheat oven to 350\\u00b0F. Line a large baking sheet with parchment paper. In a large bowl, whisk together the eggs, milk, flour, sugar, butter, and salt. Add the eggs and beat until well blended. Pour the batter into the prepared baking sheet, and let rise in the oven until the eggs are well combined, about 20 minutes. Cool on a wire rack.\", \"Meanwhile, in a small bowl, whisk together the eggs, milk, and butter. In a small bowl, whisk together the dry ingredients until smooth, about 2 minutes. Add the eggs and beat until stiff peaks form. Pour the batter into the prepared baking sheet, and let rise in the oven until the batter has risen a little, about 2 minutes. Cool on a wire rack.\", \"Meanwhile, in a small bowl, whisk together the dry ingredients until smooth, about 2 minutes. Add the dry ingredients and beat until stiff peaks form. Pour the batter into the prepared baking sheet, and let rise in the oven until the batter has risen a little, about 2 minutes. Cool on a wire rack.\", \"In a small bowl, whisk together the dry ingredients, and beat until smooth, about 2 minutes. Add the dry ingredients and beat until stiff peaks form. Pour the batter into the prepared baking sheet, and let rise in the oven until the batter has risen a little, about 2 minutes. Cool on a wire rack.\", \"In a small bowl, whisk together the dry ingredients, and beat until smooth, about 2 minutes. Add the wet ingredients and beat until stiff peaks form. Pour the batter into the prepared baking sheet, and let rise in the oven until the batter has risen a little, about 2 minutes. Cool on a wire rack.\", \"In a small bowl, whisk together the dry ingredients, and beat until smooth, about 2 minutes. Add the wet ingredients\n",
            "\n",
            "Ingredients: pasta, cheese, cream, black pepper\n",
            "Recipe Name: Cacio e Pepe\n",
            "Recipe: Cacio e Pepe | Ingredients: pasta, cheese, cream, black pepper | Instructions: [\"Preheat oven to 400\\u00b0F.\", \"In a large bowl, whisk together pasta, cream cheese, black pepper, and 1 1/2 cups water until smooth.\", \"Stir in eggs, stirring until well combined.\", \"Add remaining 1/2 cup of the water and stir until well combined.\", \"Remove from heat and add cheese.\", \"Mix in remaining 1/2 cup of the water.\", \"Pour the mixture into a saucepan over medium heat.\", \"Cook over medium heat, stirring frequently, until cheese is melted.\", \"Turn off heat and pour into a greased bowl.\", \"Sprinkle with remaining 1/4 cup of the pasta mixture.\", \"Bake at 400\\u00b0F until the cheese is golden brown, about 30 minutes.\", \"Remove from oven and cool completely.\", \"In a large bowl, whisk together egg, milk, and vanilla.\", \"Add the egg mixture to the egg mixture, whisking just until the egg mixture is completely incorporated.\", \"Remove from heat and stir in the remaining 1/4 cup of the egg mixture.\", \"Repeat with remaining egg mixture.\", \"Cool completely.\", \"In a large bowl, whisk together the cream cheese, black pepper, and 1 1/2 cups milk until smooth.\", \"Add the egg mixture to the egg mixture and mix thoroughly.\", \"Bring to a boil and reduce heat to medium-low.\", \"Drain and set aside.\", \"In a large bowl, whisk together the cream cheese, black pepper, and 1 1/2 cups milk until smooth.\", \"Add the egg mixture to the egg mixture and mix thoroughly.\", \"Bring to a boil and reduce heat to low.\", \"Drain and set aside.\", \"In a large bowl, whisk together the cream cheese, black pepper, and 1 1/2 cups milk until smooth.\", \"Add the egg mixture to the\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 23: Evaluate Using ROUGE Scores on Test Set\n",
        "print(\"EVALUATING WITH ROUGE SCORES ON TEST SET\")\n",
        "# Load ROUGE metric\n",
        "rouge = load('rouge')\n",
        "def evaluate_with_rouge(num_samples=30):\n",
        "    \"\"\"\n",
        "    Evaluate generated recipes using ROUGE scores\n",
        "    Compare generated recipes with original recipes from TEST set\n",
        "    \"\"\"\n",
        "    # Sample from TEST set (not validation)\n",
        "    sample_size = min(num_samples, len(test_df))\n",
        "    sample_df = test_df.sample(n=sample_size, random_state=42)\n",
        "    references = []\n",
        "    predictions = []\n",
        "    print(f\"Evaluating {sample_size} samples from TEST set...\")\n",
        "    for idx, row in sample_df.iterrows():\n",
        "        original = row['formatted_text']\n",
        "        # Extract prompt (recipe name and start of ingredients)\n",
        "        parts = original.split('|')\n",
        "        if len(parts) >= 2:\n",
        "            prompt = parts[0] + '|' + parts[1][:50] + '...'\n",
        "        else:\n",
        "            prompt = original[:100]\n",
        "\n",
        "        # Generate recipe\n",
        "        try:\n",
        "            generated = generate_recipe(prompt, max_length=400, temperature=0.7)\n",
        "            references.append(original)\n",
        "            predictions.append(generated)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating for prompt: {prompt[:50]}... - {str(e)}\")\n",
        "            continue\n",
        "    # Compute ROUGE scores\n",
        "    if len(predictions) > 0:\n",
        "        results = rouge.compute(predictions=predictions, references=references)\n",
        "        return results\n",
        "    else:\n",
        "        return None\n",
        "print(\"Computing ROUGE scores on test set (this may take a few minutes)...\")\n",
        "rouge_scores = evaluate_with_rouge(num_samples=30)\n",
        "if rouge_scores:\n",
        "    print(\"\\nROUGE Scores (Test Set):\")\n",
        "    print(\"=\"*70)\n",
        "    for key, value in rouge_scores.items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "else:\n",
        "    print(\"Could not compute ROUGE scores\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "3b747e617aef471abed5a021285d7008",
            "cbf044e177ff46e1925e28c273603342",
            "64ef8f67540c4ae6b050dc5b78edc096",
            "497bbeff423e4e23b6678412fe9b0506",
            "a6f5dccebfb74bbbb948de5c74522139",
            "4934108be9df417c8e3104b5b6146283",
            "1bd4231be4dd497f8ea16b60cb1ba4a2",
            "eb47b2b7e4ec44488ff99936b0e0f3cf",
            "7087a18b220941328e1e93d217ec3f19",
            "4b48771d31bd405691c98bcbdf14abd3",
            "b17d635e0501411ca42b0269a6f78d55"
          ]
        },
        "id": "aT1-R-c5x_nx",
        "outputId": "c17d2134-f208-4243-c550-3cd68e0e8334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUATING WITH ROUGE SCORES ON TEST SET\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b747e617aef471abed5a021285d7008"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing ROUGE scores on test set (this may take a few minutes)...\n",
            "Evaluating 30 samples from TEST set...\n",
            "\n",
            "ROUGE Scores (Test Set):\n",
            "======================================================================\n",
            "  rouge1: 0.2418\n",
            "  rouge2: 0.0924\n",
            "  rougeL: 0.1743\n",
            "  rougeLsum: 0.1749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 24: Quality Assessment of Generated Recipes\n",
        "print(\"QUALITY ASSESSMENT\")\n",
        "def assess_recipe_quality(recipe_text):\n",
        "    \"\"\"\n",
        "    Automated quality checks for generated recipes\n",
        "    \"\"\"\n",
        "    scores = {}\n",
        "    # Check for key sections\n",
        "    scores['has_recipe_name'] = 'recipe:' in recipe_text.lower()\n",
        "    scores['has_ingredients'] = 'ingredients:' in recipe_text.lower()\n",
        "    scores['has_instructions'] = 'instructions:' in recipe_text.lower()\n",
        "    # Check length (reasonable recipe should be substantial)\n",
        "    word_count = len(recipe_text.split())\n",
        "    scores['adequate_length'] = word_count > 30\n",
        "    # Check for cooking verbs\n",
        "    cooking_verbs = ['mix', 'bake', 'cook', 'heat', 'add', 'stir', 'combine', 'serve', 'pour', 'chop', 'blend']\n",
        "    scores['has_cooking_verbs'] = any(verb in recipe_text.lower() for verb in cooking_verbs)\n",
        "    # Check for measurements\n",
        "    measurements = ['cup', 'tablespoon', 'teaspoon', 'gram', 'ounce', 'pound', 'oz', 'ml', 'tbsp', 'tsp']\n",
        "    scores['has_measurements'] = any(measure in recipe_text.lower() for measure in measurements)\n",
        "    # Overall score\n",
        "    scores['overall_score'] = sum(scores.values()) / len(scores)\n",
        "    return scores\n",
        "# Assess all generated recipes\n",
        "print(\"Assessing quality of generated recipes...\")\n",
        "quality_results = []\n",
        "for item in generated_recipes:\n",
        "    scores = assess_recipe_quality(item['generated_recipe'])\n",
        "    quality_results.append(scores)\n",
        "# Calculate average scores\n",
        "if quality_results:\n",
        "    avg_scores = {\n",
        "        key: np.mean([r[key] for r in quality_results])\n",
        "        for key in quality_results[0].keys()\n",
        "    }\n",
        "    print(\"\\nAverage Quality Scores:\")\n",
        "    for key, value in avg_scores.items():\n",
        "        print(f\"  {key}: {value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldk1fLhLx_2-",
        "outputId": "e42f59f1-4078-400f-97b4-1360f390d932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUALITY ASSESSMENT\n",
            "Assessing quality of generated recipes...\n",
            "\n",
            "Average Quality Scores:\n",
            "  has_recipe_name: 1.00\n",
            "  has_ingredients: 1.00\n",
            "  has_instructions: 1.00\n",
            "  adequate_length: 1.00\n",
            "  has_cooking_verbs: 1.00\n",
            "  has_measurements: 0.20\n",
            "  overall_score: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 25: Save Generated Recipes to CSV\n",
        "print(\"SAVING GENERATED RECIPES\")\n",
        "# Create DataFrame with generated recipes\n",
        "recipes_df = pd.DataFrame(generated_recipes)\n",
        "# Add quality scores\n",
        "recipes_df['quality_score'] = [assess_recipe_quality(r['generated_recipe'])['overall_score']\n",
        "for r in generated_recipes]\n",
        "# Save to CSV\n",
        "recipes_df.to_csv('generated_recipes.csv', index=False)\n",
        "print(\"Generated recipes saved to 'generated_recipes.csv'\")\n",
        "# Display summary\n",
        "print(f\"\\nGenerated {len(recipes_df)} recipes\")\n",
        "print(f\"Average quality score: {recipes_df['quality_score'].mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KI-tuuW7hYd",
        "outputId": "e5ec7553-827a-4ba6-a64b-dd8c262a1672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVING GENERATED RECIPES\n",
            "Generated recipes saved to 'generated_recipes.csv'\n",
            "\n",
            "Generated 5 recipes\n",
            "Average quality score: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 26: Save the Fine-tuned Model\n",
        "print(\"SAVING FINE-TUNED MODEL\")\n",
        "# Create output directory\n",
        "output_dir = './gpt2_recipe_model'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "# Save model and tokenizer\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model saved to: {output_dir}\")\n",
        "print(\"\\nSaved files:\")\n",
        "for file in os.listdir(output_dir):\n",
        "    print(f\"  - {file}\")\n",
        "print(\"\\nTo load this model later:\")\n",
        "print(f\"  tokenizer = GPT2Tokenizer.from_pretrained('{output_dir}')\")\n",
        "print(f\"  model = GPT2LMHeadModel.from_pretrained('{output_dir}')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO2I6W4-7hk7",
        "outputId": "900b20e5-7f9c-48e4-9458-08e8f22f49e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVING FINE-TUNED MODEL\n",
            "Model saved to: ./gpt2_recipe_model\n",
            "\n",
            "Saved files:\n",
            "  - config.json\n",
            "  - model.safetensors\n",
            "  - merges.txt\n",
            "  - vocab.json\n",
            "  - special_tokens_map.json\n",
            "  - tokenizer_config.json\n",
            "  - generation_config.json\n",
            "\n",
            "To load this model later:\n",
            "  tokenizer = GPT2Tokenizer.from_pretrained('./gpt2_recipe_model')\n",
            "  model = GPT2LMHeadModel.from_pretrained('./gpt2_recipe_model')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 27: Create and Save Training Summary\n",
        "print(\"CREATING TRAINING SUMMARY\")\n",
        "# Compile all metrics\n",
        "summary = {\n",
        "    'task': 'Recipe Generation',\n",
        "    'model_architecture': 'GPT-2 (Decoder-only)',\n",
        "    'model_name': model_name,\n",
        "    'dataset_size': len(df_clean),\n",
        "    'train_size': len(train_df),\n",
        "    'validation_size': len(val_df),\n",
        "    'test_size': len(test_df),\n",
        "    'split_percentages': {\n",
        "        'train': f\"{len(train_df)/(len(train_df)+len(val_df)+len(test_df))*100:.1f}%\",\n",
        "        'validation': f\"{len(val_df)/(len(train_df)+len(val_df)+len(test_df))*100:.1f}%\",\n",
        "        'test': f\"{len(test_df)/(len(train_df)+len(val_df)+len(test_df))*100:.1f}%\"\n",
        "    },\n",
        "    'training_config': {\n",
        "        'learning_rate': training_args.learning_rate,\n",
        "        'batch_size': training_args.per_device_train_batch_size,\n",
        "        'gradient_accumulation': training_args.gradient_accumulation_steps,\n",
        "        'effective_batch_size': training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps,\n",
        "        'num_epochs': training_args.num_train_epochs,\n",
        "        'max_length': 512,\n",
        "    },\n",
        "    'training_results': {\n",
        "        'final_training_loss': float(train_result.training_loss),\n",
        "        'training_time_seconds': float(train_result.metrics['train_runtime']),\n",
        "        'training_time_minutes': float(train_result.metrics['train_runtime'] / 60),\n",
        "    },\n",
        "    'validation_results': {\n",
        "        'loss': float(eval_results['eval_loss']),\n",
        "    },\n",
        "    'generation_quality': {\n",
        "        'average_quality_score': float(recipes_df['quality_score'].mean()) if len(recipes_df) > 0 else 0,\n",
        "        'num_recipes_generated': len(recipes_df),\n",
        "    }\n",
        "}\n",
        "# Add ROUGE scores if available (these are from TEST set)\n",
        "if rouge_scores:\n",
        "    summary['test_rouge_scores'] = {k: float(v) for k, v in rouge_scores.items()}\n",
        "# Save summary as JSON\n",
        "with open('training_summary.json', 'w') as f:\n",
        "    json.dump(summary, f, indent=4)\n",
        "print(\"Training Summary:\")\n",
        "print(json.dumps(summary, indent=2))\n",
        "print(\"\\nSummary saved to 'training_summary.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I4NOH3ix_6R",
        "outputId": "724f45fc-70e3-4a75-ff95-84393e5d1b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATING TRAINING SUMMARY\n",
            "Training Summary:\n",
            "{\n",
            "  \"task\": \"Recipe Generation\",\n",
            "  \"model_architecture\": \"GPT-2 (Decoder-only)\",\n",
            "  \"model_name\": \"gpt2\",\n",
            "  \"dataset_size\": 5000,\n",
            "  \"train_size\": 4000,\n",
            "  \"validation_size\": 500,\n",
            "  \"test_size\": 500,\n",
            "  \"split_percentages\": {\n",
            "    \"train\": \"80.0%\",\n",
            "    \"validation\": \"10.0%\",\n",
            "    \"test\": \"10.0%\"\n",
            "  },\n",
            "  \"training_config\": {\n",
            "    \"learning_rate\": 5e-05,\n",
            "    \"batch_size\": 4,\n",
            "    \"gradient_accumulation\": 4,\n",
            "    \"effective_batch_size\": 16,\n",
            "    \"num_epochs\": 3,\n",
            "    \"max_length\": 512\n",
            "  },\n",
            "  \"training_results\": {\n",
            "    \"final_training_loss\": 2.594430430094401,\n",
            "    \"training_time_seconds\": 892.376,\n",
            "    \"training_time_minutes\": 14.872933333333332\n",
            "  },\n",
            "  \"validation_results\": {\n",
            "    \"loss\": 2.1553285121917725\n",
            "  },\n",
            "  \"generation_quality\": {\n",
            "    \"average_quality_score\": 0.8666666666666668,\n",
            "    \"num_recipes_generated\": 5\n",
            "  },\n",
            "  \"test_rouge_scores\": {\n",
            "    \"rouge1\": 0.24180729908162427,\n",
            "    \"rouge2\": 0.09237760047589866,\n",
            "    \"rougeL\": 0.174345544124981,\n",
            "    \"rougeLsum\": 0.17493291462657146\n",
            "  }\n",
            "}\n",
            "\n",
            "Summary saved to 'training_summary.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 28: Final Summary and Output Files\n",
        "print(\"TASK 02 COMPLETED SUCCESSFULLY! ✓\")\n",
        "print(\"\\n Generated Files:\")\n",
        "print(\"  1. generated_recipes.csv - Sample generated recipes with quality scores\")\n",
        "print(\"  2. training_summary.json - Complete training metrics and configuration\")\n",
        "print(\"  3. ./gpt2_recipe_model/ - Fine-tuned GPT-2 model checkpoint\")\n",
        "print(\"  4. ./results/ - Training checkpoints and logs\")\n",
        "print(\"\\n Final Metrics:\")\n",
        "print(f\"  Training Loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"  Validation Loss: {eval_results['eval_loss']:.4f}\")\n",
        "if rouge_scores:\n",
        "    print(f\"\\n  Test Set ROUGE Scores:\")\n",
        "    print(f\"    ROUGE-1: {rouge_scores.get('rouge1', 0):.4f}\")\n",
        "    print(f\"    ROUGE-2: {rouge_scores.get('rouge2', 0):.4f}\")\n",
        "    print(f\"    ROUGE-L: {rouge_scores.get('rougeL', 0):.4f}\")\n",
        "print(f\"\\n  Average Quality Score: {recipes_df['quality_score'].mean():.2f}/1.00\")\n",
        "print(\"\\n Dataset Split:\")\n",
        "print(f\"  Train: {len(train_df)} samples ({len(train_df)/(len(train_df)+len(val_df)+len(test_df))*100:.1f}%)\")\n",
        "print(f\"  Validation: {len(val_df)} samples ({len(val_df)/(len(train_df)+len(val_df)+len(test_df))*100:.1f}%)\")\n",
        "print(f\"  Test: {len(test_df)} samples ({len(test_df)/(len(train_df)+len(val_df)+len(test_df))*100:.1f}%)\")\n",
        "print(\"\\n  Training Time:\")\n",
        "print(f\"  Total: {train_result.metrics['train_runtime']:.2f} seconds ({train_result.metrics['train_runtime']/60:.2f} minutes)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgksSqR-8_QG",
        "outputId": "955db5e3-5d26-475c-e104-7955177ac2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TASK 02 COMPLETED SUCCESSFULLY! ✓\n",
            "\n",
            " Generated Files:\n",
            "  1. generated_recipes.csv - Sample generated recipes with quality scores\n",
            "  2. training_summary.json - Complete training metrics and configuration\n",
            "  3. ./gpt2_recipe_model/ - Fine-tuned GPT-2 model checkpoint\n",
            "  4. ./results/ - Training checkpoints and logs\n",
            "\n",
            " Final Metrics:\n",
            "  Training Loss: 2.5944\n",
            "  Validation Loss: 2.1553\n",
            "\n",
            "  Test Set ROUGE Scores:\n",
            "    ROUGE-1: 0.2418\n",
            "    ROUGE-2: 0.0924\n",
            "    ROUGE-L: 0.1743\n",
            "\n",
            "  Average Quality Score: 0.87/1.00\n",
            "\n",
            " Dataset Split:\n",
            "  Train: 4000 samples (80.0%)\n",
            "  Validation: 500 samples (10.0%)\n",
            "  Test: 500 samples (10.0%)\n",
            "\n",
            "  Training Time:\n",
            "  Total: 892.38 seconds (14.87 minutes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 29: Save Fine-tuned Model and Tokenizer\n",
        "def save_fine_tuned_model(model, tokenizer, save_directory=\"./gpt2_recipe_fine_tuned\"):\n",
        "    \"\"\"\n",
        "    Save the fine-tuned model and tokenizer to the specified directory\n",
        "    Args:\n",
        "        model: The fine-tuned GPT-2 model\n",
        "        tokenizer: The tokenizer used for training\n",
        "        save_directory: Directory to save the model and tokenizer\n",
        "    \"\"\"\n",
        "    # Create directory if it doesn't exist\n",
        "    if not os.path.exists(save_directory):\n",
        "        os.makedirs(save_directory)\n",
        "    # Save model and tokenizer\n",
        "    model.save_pretrained(save_directory)\n",
        "    tokenizer.save_pretrained(save_directory)\n",
        "    print(f\" Model and tokenizer successfully saved to: {save_directory}\")\n",
        "    print(f\" Files saved:\")\n",
        "    print(f\"   - {save_directory}/config.json\")\n",
        "    print(f\"   - {save_directory}/pytorch_model.bin\")\n",
        "    print(f\"   - {save_directory}/tokenizer.json\")\n",
        "    print(f\"   - {save_directory}/vocab.json\")\n",
        "    print(f\"   - {save_directory}/merges.txt\")\n",
        "    print(f\"   - {save_directory}/special_tokens_map.json\")\n",
        "    return save_directory\n",
        "# Save the fine-tuned model\n",
        "model_save_path = save_fine_tuned_model(model, tokenizer)\n",
        "\n",
        "# Additional: Save training configuration\n",
        "training_config = {\n",
        "    \"model_name\": \"gpt2\",\n",
        "    \"fine_tuned_on\": \"recipe_dataset\",\n",
        "    \"dataset_size\": len(df),\n",
        "    \"training_epochs\": training_args.num_train_epochs,\n",
        "    \"learning_rate\": training_args.learning_rate,\n",
        "    \"batch_size\": training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps,\n",
        "    \"max_length\": 512,\n",
        "    \"save_directory\": model_save_path,\n",
        "    \"training_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "}\n",
        "config_save_path = os.path.join(model_save_path, \"training_config.json\")\n",
        "with open(config_save_path, 'w') as f:\n",
        "    json.dump(training_config, f, indent=4)\n",
        "print(f\" Training configuration saved to: {config_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjcA2Oxg8_eA",
        "outputId": "379926d7-ce81-4e2f-f26b-430bd29f44c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model and tokenizer successfully saved to: ./gpt2_recipe_fine_tuned\n",
            " Files saved:\n",
            "   - ./gpt2_recipe_fine_tuned/config.json\n",
            "   - ./gpt2_recipe_fine_tuned/pytorch_model.bin\n",
            "   - ./gpt2_recipe_fine_tuned/tokenizer.json\n",
            "   - ./gpt2_recipe_fine_tuned/vocab.json\n",
            "   - ./gpt2_recipe_fine_tuned/merges.txt\n",
            "   - ./gpt2_recipe_fine_tuned/special_tokens_map.json\n",
            " Training configuration saved to: ./gpt2_recipe_fine_tuned/training_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 30: Model Loading Function (For Future Use)\n",
        "def load_fine_tuned_model(model_directory=\"./gpt2_recipe_fine_tuned\"):\n",
        "    \"\"\"\n",
        "    Load the fine-tuned model and tokenizer from the specified directory\n",
        "\n",
        "    Args:\n",
        "        model_directory: Directory containing the saved model and tokenizer\n",
        "\n",
        "    Returns:\n",
        "        model: Loaded GPT-2 model\n",
        "        tokenizer: Loaded tokenizer\n",
        "    \"\"\"\n",
        "    print(f\"Loading fine-tuned model from: {model_directory}\")\n",
        "    # Check if directory exists\n",
        "    if not os.path.exists(model_directory):\n",
        "        raise FileNotFoundError(f\"Model directory '{model_directory}' not found!\")\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_directory)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_directory)\n",
        "    # Move model to appropriate device\n",
        "    model = model.to(device)\n",
        "    print(\" Model and tokenizer loaded successfully!\")\n",
        "    print(f\" Model parameters: {model.num_parameters():,}\")\n",
        "    print(f\" Using device: {device}\")\n",
        "    return model, tokenizer\n",
        "# Test loading the saved model\n",
        "print(\"TESTING MODEL LOADING FUNCTION\")\n",
        "try:\n",
        "    # Load the model we just saved\n",
        "    loaded_model, loaded_tokenizer = load_fine_tuned_model(model_save_path)\n",
        "    # Test generation with loaded model\n",
        "    test_prompt = \"Recipe: Test Chocolate Cake | Ingredients:\"\n",
        "    print(f\"\\nTesting generation with loaded model...\")\n",
        "    print(f\"Prompt: {test_prompt}\")\n",
        "    # Generate with loaded model\n",
        "    input_ids = loaded_tokenizer.encode(test_prompt, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        output = loaded_model.generate(\n",
        "            input_ids,\n",
        "            max_length=200,\n",
        "            temperature=0.8,\n",
        "            do_sample=True,\n",
        "            pad_token_id=loaded_tokenizer.eos_token_id\n",
        "        )\n",
        "    generated_text = loaded_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    print(f\"Generated: {generated_text[:200]}...\")\n",
        "    print(\"\\n Model loading test successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYoKmaog_p2g",
        "outputId": "cf95161e-9865-4040-fad8-9e002345501d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTING MODEL LOADING FUNCTION\n",
            "Loading fine-tuned model from: ./gpt2_recipe_fine_tuned\n",
            " Model and tokenizer loaded successfully!\n",
            " Model parameters: 124,439,808\n",
            " Using device: cuda\n",
            "\n",
            "Testing generation with loaded model...\n",
            "Prompt: Recipe: Test Chocolate Cake | Ingredients:\n",
            "Generated: Recipe: Test Chocolate Cake | Ingredients: [\"chocolate\", \"butter\", \"mixed cream\", \"egg yolks\", \"ground cinnamon\", \"salt\", \"baking powder\", \"powdered sugar\", \"vanilla extract\", \"water\", \"ground nutmeg\"...\n",
            "\n",
            " Model loading test successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 31: Export Model to Google Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Create backup directory in Drive\n",
        "    drive_backup_path = \"/content/drive/MyDrive/gpt2_recipe_model\"\n",
        "    if not os.path.exists(drive_backup_path):\n",
        "        os.makedirs(drive_backup_path)\n",
        "    # Copy model to Drive\n",
        "    import shutil\n",
        "    shutil.copytree(model_save_path, drive_backup_path, dirs_exist_ok=True)\n",
        "    print(f\" Model backed up to Google Drive: {drive_backup_path}\")\n",
        "except ImportError:\n",
        "    print(\"  Not running in Google Colab - skipping Drive backup\")\n",
        "except Exception as e:\n",
        "    print(f\"  Could not backup to Google Drive: {e}\")\n",
        "print(\"Model Saved Successfully\")\n",
        "print(\"Fine-tuned model is now saved and can be loaded later using:\")\n",
        "print(f\"model, tokenizer = load_fine_tuned_model('{model_save_path}')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "GJIhQ-E4_qD8",
        "outputId": "9e9e9c81-e8ba-4230-c082-e79b3608af63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "  Could not backup to Google Drive: name 'os' is not defined\n",
            "Model Saved Successfully\n",
            "Fine-tuned model is now saved and can be loaded later using:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_save_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2629819636.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Saved Successfully\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fine-tuned model is now saved and can be loaded later using:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"model, tokenizer = load_fine_tuned_model('{model_save_path}')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_save_path' is not defined"
          ]
        }
      ]
    }
  ]
}